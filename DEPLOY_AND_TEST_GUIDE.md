# Quick Start: Deploy & Test Streaming on Vercel

## ğŸ“‹ Pre-Deployment Checklist

### âœ… Code Changes (Already Done)
- [x] Streaming endpoint implemented (`/api/analysis/:id/start-streaming`)
- [x] Client updated to use streaming endpoint
- [x] Server-Sent Events (SSE) headers configured
- [x] OpenAI streaming enabled
- [x] Database status tracking added

### ğŸ” Files to Review Before Deploy
1. `api/index.js` - Vercel serverless function (âœ… already built)
2. `vercel.json` - Routes configuration (âœ… looks good)
3. `server/streaming-analysis.ts` - Core streaming logic (âœ… implemented)

---

## ğŸš€ Step 1: Deploy to Vercel

### Option A: Deploy via Vercel CLI
```bash
# Install Vercel CLI if you haven't
npm i -g vercel

# Login to Vercel
vercel login

# Deploy to production
vercel --prod
```

### Option B: Deploy via Git (Recommended)
```bash
# Add all changes
git add STREAMING_TEST_REPORT.md test-vercel-streaming.sh

# Commit
git commit -m "Add streaming implementation for Vercel timeout fix"

# Push to GitHub (triggers automatic Vercel deployment)
git push origin main
```

### Option C: Deploy via Vercel Dashboard
1. Go to https://vercel.com
2. Import your GitHub repository
3. Configure environment variables (see below)
4. Deploy

---

## âš™ï¸ Step 2: Configure Environment Variables

Go to Vercel Dashboard â†’ Your Project â†’ Settings â†’ Environment Variables

**Required:**
```
DATABASE_URL=postgresql://...
OPENAI_API_KEY=sk-...
SESSION_SECRET=your-random-secret-key
NODE_ENV=production
```

**Optional (for R2 Storage):**
```
R2_ACCOUNT_ID=...
R2_ACCESS_KEY_ID=...
R2_SECRET_ACCESS_KEY=...
R2_BUCKET_NAME=getglow-images
R2_PUBLIC_URL=https://...
```

âš ï¸ **Important:** After adding env vars, trigger a new deployment!

---

## ğŸ§ª Step 3: Test the Streaming Implementation

### Manual Test (Web Browser)

1. **Visit your Vercel URL**
   ```
   https://your-app.vercel.app
   ```

2. **Upload a face image**
   - Click the upload area
   - Select a face photo
   - Wait for upload to complete

3. **Start Analysis**
   - Click "Start Analysis" button
   - Watch the animated loader

4. **Monitor in Browser DevTools**
   - Open DevTools (F12 or Cmd+Option+I)
   - Go to **Network** tab
   - Filter by "eventsource" or look for `/start-streaming`
   - You should see:
     - Status: `200 OK`
     - Type: `eventsource` or `text/event-stream`
     - Data streaming in real-time

5. **Check Console**
   - Look for logs like:
     ```
     ğŸ”„ Polling for analysis: 123
     ğŸ“Š Analysis status: processing
     âœ… Polling stopped. Final status: completed
     ```

6. **Verify Results**
   - You should be redirected to `/history` page
   - Your analysis should appear with scores

### Automated Test (Command Line)

```bash
# Replace with your actual Vercel URL
./test-vercel-streaming.sh https://your-app.vercel.app
```

Expected output:
```
ğŸ§ª GetGlow - Vercel Streaming Test Script
==========================================

Testing deployment: https://your-app.vercel.app

1ï¸âƒ£  Testing API accessibility...
âœ… API is accessible

2ï¸âƒ£  Checking if required environment variables are set...
âœ… API is functioning (env vars likely OK)

3ï¸âƒ£  Testing upload endpoint...
   Creating a test image...
   Uploading test image...
âœ… Upload successful! Analysis ID: 123

4ï¸âƒ£  Testing streaming analysis endpoint...
   Starting streaming analysis...
   ğŸ“¡ Event: progress
   âœ… Analysis started
   ğŸ“Š Progress: 10%
   ğŸ“Š Progress: 20%
   ...
   âœ… Analysis complete! Received results.
   â±ï¸  Total time: 25s
   ğŸ¯ Overall Score: 75

5ï¸âƒ£  Verifying results in database...
âœ… Analysis status in database: completed
âœ… Results saved to database (Overall Score: 75)

==========================================
ğŸ‰ All tests passed!
```

---

## ğŸ“Š Step 4: Monitor Vercel Logs

1. Go to **Vercel Dashboard** â†’ Your Project â†’ **Logs**

2. **Watch for these log entries:**
   ```
   [HANDLER] POST /api/analysis/123/start-streaming
   ğŸ“¥ Downloading image from R2: https://...
   âœ… Downloaded to: /tmp/temp_123.jpg
   âœ… Streaming analysis completed, 156 chunks
   ```

3. **Look for errors:**
   - âŒ "Function timeout" â†’ Streaming not working correctly
   - âŒ "OpenAI API error" â†’ Check API key or quota
   - âŒ "Database error" â†’ Check DATABASE_URL

---

## ğŸ¯ Success Indicators

### âœ… Streaming is Working When You See:
1. **No timeout errors** (previously would timeout at 10s)
2. **SSE connection stays open** for 20-60 seconds
3. **Progress events** stream to client
4. **Analysis completes** and results are saved
5. **Database status** changes from `processing` â†’ `completed`
6. **Vercel logs** show "Streaming analysis completed"

### âŒ Streaming is NOT Working If:
1. Request times out after 10 seconds
2. Error: "504 Gateway Timeout"
3. No progress events in browser console
4. Analysis status stuck at "processing"
5. Vercel logs show timeout errors

---

## ğŸ› Troubleshooting

### Problem: Still getting timeouts

**Check:**
1. Is the client calling `/api/analysis/:id/start-streaming`? 
   - âœ… Yes: `client/src/pages/home.tsx` line 62
2. Are SSE headers set correctly?
   - âœ… Yes: `server/streaming-analysis.ts` line 19-23
3. Is OpenAI streaming enabled?
   - âœ… Yes: `stream: true` in API call

**Solutions:**
- Verify environment variables in Vercel
- Check Vercel function logs for specific errors
- Test OpenAI API key locally first

### Problem: Analysis starts but never completes

**Check:**
1. Database status field
   ```bash
   # Check database directly
   psql $DATABASE_URL -c "SELECT id, status, overallScore FROM analyses ORDER BY id DESC LIMIT 5;"
   ```
2. Vercel logs for errors during analysis
3. OpenAI API quota/limits

**Solutions:**
- Check if OpenAI response is valid JSON
- Verify database connection is stable
- Review error logs in detail

### Problem: Can't see streaming events

**Solutions:**
1. Use Chrome/Firefox DevTools Network tab
2. Filter by "EventSource" or "eventsource"
3. Look at raw response data
4. Check if SSE is blocked by ad-blockers

---

## ğŸ“ˆ Performance Metrics

### Expected Performance:
- **Upload:** ~1-3 seconds
- **Streaming Analysis:** 20-40 seconds (no timeout!)
- **Database Save:** <1 second
- **Total:** ~25-45 seconds

### vs. Old Non-Streaming:
- **Old:** Timeout at 10 seconds âŒ
- **New:** Completes in 25-45 seconds âœ…

---

## ğŸ“ Next Steps After Successful Test

1. âœ… Confirm streaming works on Vercel
2. ğŸ“ Document any edge cases discovered
3. ğŸ¨ Consider adding progress bar based on chunk count
4. ğŸ“Š Monitor OpenAI API usage and costs
5. ğŸ”” Set up Vercel alerts for errors
6. ğŸ§ª Test with various image sizes and formats
7. ğŸ“– Update user documentation if needed

---

## ğŸ“ Quick Reference

**Streaming Endpoint:**
```
POST /api/analysis/:id/start-streaming
```

**Client Code:**
```typescript
// client/src/pages/home.tsx line 62
await fetch(`/api/analysis/${analysisId}/start-streaming`, {
  method: 'POST',
});
```

**Server Code:**
```typescript
// server/streaming-analysis.ts
export async function performStreamingAnalysis(...)
```

**Test Script:**
```bash
./test-vercel-streaming.sh https://your-app.vercel.app
```

---

**Last Updated:** January 2025
**Status:** ğŸŸ¢ Ready for Vercel Testing
